{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dxde8wvyC3nU"
      },
      "outputs": [],
      "source": [
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gD1hZTnIC8VM"
      },
      "outputs": [],
      "source": [
        "x = [1, -1]\n",
        "b = [0., 0., 0.]\n",
        "c = [0., 0.]\n",
        "w = [[1., 1., 1.], [-1., -1., -1.]]\n",
        "v = [[1., 1.], [-1., -1.], [-1., -1.]]\n",
        "t = [1, 0]\n",
        "k1 = [0.] * 3\n",
        "k2 = [0.] * 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Paucs7peDB5i"
      },
      "outputs": [],
      "source": [
        "# softmax activation\n",
        "def softmax(x):\n",
        "    e_x = [math.exp(i) for i in x]\n",
        "    sum_e_x = sum(e_x)\n",
        "    return [i / sum_e_x for i in e_x]\n",
        "\n",
        "def forward_propagation(x, w, b, v, c):\n",
        "  \n",
        "  for j in range(len(k1)):\n",
        "    for i in range(len(x)):\n",
        "      k1[j] += w[i][j] * x[i]\n",
        "    k1[j] += b[j]\n",
        "\n",
        "  # sigmoid activation\n",
        "  h = [1 / (1 + math.exp(-1*k1[i])) for i in range(len(k1))]\n",
        "\n",
        "  # k2 = vh + c\n",
        "  \n",
        "  for j in range(len(k2)):\n",
        "    for i in range(len(h)):\n",
        "      k2[j] += v[i][j] * h[i]\n",
        "    k2[j] += c[j]\n",
        "\n",
        "  y = softmax(k2)\n",
        "\n",
        "  return y, h\n",
        "\n",
        "y, h = forward_propagation(x, w, b, v, c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZcQeD1JcBe2"
      },
      "outputs": [],
      "source": [
        "def back_propagation(x, h, y, t):\n",
        "    dL_dk2 = [y[i] - t[i] for i in range(len(y))]\n",
        "\n",
        "    dL_dv = [[dL_dk2[j] * h[i] for j in range(len(dL_dk2))] for i in range(len(h))]\n",
        "\n",
        "    dL_dc = dL_dk2\n",
        "\n",
        "    dL_dh = [sum(dL_dk2[j] * v[i][j] for j in range(len(dL_dk2))) for i in range(len(h))]\n",
        "    dh_dk1 = [h[i] * (1 - h[i]) for i in range(len(h))]  # derivative of sigmoid function\n",
        "\n",
        "    dL_dk1 = [dL_dh[i] * dh_dk1[i] for i in range(len(h))]\n",
        "\n",
        "    dL_dw = [[dL_dk1[j] * x[i] for j in range(len(dL_dk1))] for i in range(len(x))]\n",
        "\n",
        "    dL_db = dL_dk1\n",
        "\n",
        "    return dL_dv, dL_dc, dL_dw, dL_db"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rk0JsFMIicMz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hx6wgmJEdovr"
      },
      "outputs": [],
      "source": [
        "dL_dv, dL_dc, dL_dw, dL_db = back_propagation(x, h, y, t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTV9-HM3d2eV",
        "outputId": "5a62277f-6daa-4a7e-8a41-7878d30f0ef5"
      },
      "outputs": [],
      "source": [
        "print(\"Derivatives wrt w:\", dL_dw)\n",
        "print(\"Derivatives wrt b1:\", dL_db)\n",
        "print(\"Derivatives wrt v:\", dL_dv)\n",
        "print(\"Derivatives wrt c:\", dL_dc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AlN2ARbehC1"
      },
      "source": [
        "### question4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from data import load_synth\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvuL2rleejTy"
      },
      "outputs": [],
      "source": [
        "(xtrain, ytrain), (xval, yval), num_cls = load_synth()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def initialize_parameters(input_dim, hidden_dim, output_dim):\n",
        "    ww = [[random.uniform(-0.1, 0.1) for _ in range(hidden_dim)] for _ in range(input_dim)]\n",
        "    b = [0.0 for _ in range(hidden_dim)]\n",
        "    v = [[random.uniform(-0.1, 0.1) for _ in range(output_dim)] for _ in range(hidden_dim)]\n",
        "    c = [0.0 for _ in range(output_dim)]\n",
        "    return w, b, v, c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def min_max_scale(data):\n",
        "    global_min = min(min(row) for row in data)\n",
        "    global_max = max(max(row) for row in data)\n",
        "\n",
        "    # Scale data to [-1, 1] range\n",
        "    scaled_data = []\n",
        "    for row in data:\n",
        "        scaled_row = [2 * ((x - global_min) / (global_max - global_min)) - 1 for x in row]\n",
        "        scaled_data.append(scaled_row)\n",
        "    \n",
        "    return scaled_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1sYMOrfj0pu"
      },
      "outputs": [],
      "source": [
        "def convert_to_one_hot(y, num_classes):\n",
        "    one_hot = [[1 if i == j else 0 for j in range(num_classes)] for i in y]\n",
        "    return one_hot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iStH8RrkHsU5"
      },
      "outputs": [],
      "source": [
        "def calculate_loss(y, t):\n",
        "  loss = 0\n",
        "  for j in range(len(t)):\n",
        "    if t[j] == 1:\n",
        "        loss -= (-1)* math.log(y[j]+ 1e-9) # add a small constant to prevent log(0)\n",
        "    \n",
        "  return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6asz8tCakLtn"
      },
      "outputs": [],
      "source": [
        "def update_parameters(w, b, v, c, dL_dw, dL_db, dL_dv, dL_dc, learning_rate):\n",
        "    for i in range(len(w)):\n",
        "        for j in range(len(w[i])):\n",
        "            w[i][j] -= learning_rate * dL_dw[i][j]\n",
        "            b[j] -= learning_rate * dL_db[j]\n",
        "    for i in range(len(v)):\n",
        "        for j in range(len(v[i])):\n",
        "            v[i][j] -= learning_rate * dL_dv[i][j]\n",
        "            c[j] -= learning_rate * dL_dc[j]\n",
        "    return w, b, v, c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def train_model(x_train, y_train, num_classes, epochs, learning_rate):\n",
        "    # Normalize input data\n",
        "    x_train = min_max_scale(x_train)\n",
        "\n",
        "    # Convert labels to one-hot encoding\n",
        "    y_train_one_hot = convert_to_one_hot(y_train, num_classes)\n",
        "\n",
        "    # Initialize parameters\n",
        "    w, b, v, c = initialize_parameters(2, 3, 2)\n",
        "\n",
        "    # Training process\n",
        "    losses = []\n",
        "    for x, t in zip(x_train, y_train_one_hot):\n",
        "\n",
        "        y, h = forward_propagation(x, w, b, v, c)\n",
        "\n",
        "        \n",
        "        loss = calculate_loss(y, t)\n",
        "        losses.append(loss) \n",
        "\n",
        "        # backward propagation to get gradients\n",
        "        dL_dv, dL_dc, dL_dw, dL_db = back_propagation(x, h, y, t)\n",
        "\n",
        "        # update weights and biases\n",
        "        w, b, v, c = update_parameters(w, b, v, c, dL_dw, dL_db, dL_dv, dL_dc, learning_rate)\n",
        "\n",
        "    plt.plot(losses, label='Training Loss')\n",
        "    plt.xlabel('Training Instances')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Loss per Training Instance')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "epochs = 100\n",
        "learning_rate = 0.01\n",
        "\n",
        "train_model(xtrain, ytrain, num_cls, epochs, learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
